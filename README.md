# ğŸŒ¿ AI-POWERED CROP DISEASE PREDICTION

**DEEP LEARNING LAB (20XD68)**  
**Developed by:**  
ğŸ‘©â€ğŸ’» Akila R (22PD04)  
ğŸ‘¨â€ğŸ’» Sujan S (22PD35)

---

## ğŸ§© Problem Statement

Crop diseases threaten agricultural productivity and often lead to economic losses. Traditional detection methods are slow, labor-intensive, and heavily reliant on expert knowledge, often ignoring critical environmental conditions.  
This project proposes an intelligent, scalable system using **Vision Transformers (ViT)** and environmental features for **multimodal disease prediction**, aiding timely decision-making in precision agriculture.

---

## ğŸ“„ Abstract

This project presents a **Multimodal Deep Learning Framework** combining:

- ğŸŒ¿ **Leaf Image Analysis** using Vision Transformer (ViT)  
- ğŸŒ¡ï¸ **Environmental Sensor Data** (e.g., temperature, humidity, soil moisture)

A **cross-attention mechanism** fuses both modalities, enhancing classification performance.  
This intelligent and scalable system helps farmers detect crop diseases early and accurately, advancing smart agriculture.

---

## ğŸ“Š Dataset Description

The dataset is sourced from Kaggle:  
ğŸ”— [Multimodal Plant Disease Dataset by Subham Divakar](https://www.kaggle.com/datasets/shubhamdivakar/multimodal-plant-disease-dataset-by-subham-divakar)

Each sample includes:

- **Leaf Images**: High-resolution RGB images labeled with disease categories.
- **Numerical Features**: 7 tabular features (e.g., temperature, humidity, pH, rainfall).

> All data are stored in `mapped_data_with_images.csv`, with rows linking image paths and environmental attributes.  
> Dataset split: **80% training**, **20% testing** (stratified sampling).

---

## ğŸ“š Literature Study

**Paper Title:**  
_A Channel Attention-Driven Optimized CNN for Efficient Early Detection of Plant Diseases in Resource-Constrained Environment_  
**Authors:** Sana Parez, Naqqash Dilshad, Jong Weon Lee  
ğŸ”— [DOI Link](https://doi.org/10.3390/agriculture15020127)

âœ… The study's lightweight LeafNet CNN inspired our decision to use efficient architectures and focus on **multimodal fusion** for performance enhancement.

---

## ğŸ› ï¸ Tools and Technologies

### Development Environment

- Python 3.x  
- Jupyter Notebook / VS Code  
- Google Colab  
- Git & GitHub  
- Streamlit (web app)  
- Google Gemini (via LangChain)  

### Key Libraries

| Category | Libraries |
|----------|-----------|
| **Data** | pandas, numpy, scikit-learn |
| **Visualization** | matplotlib, seaborn |
| **Computer Vision** | OpenCV, PIL |
| **Deep Learning** | PyTorch, torchvision, EfficientNet, ResNet50, MobileNetV2, ViT |
| **Voice/Chat AI** | speech_recognition, pyttsx3, langchain_google_genai |

---

## ğŸ§  Methods & Implementation

### 1. Preprocessing

- **Images**: Resized (224Ã—224), augmented (flip, rotation), normalized  
- **Numerical Data**: Standard Scaler used; class labels encoded  

### 2. Model Architecture

#### Multimodal Neural Network

- **Visual Branch**: ViT-B_16 (ImageNet pretrained)
- **Numerical Branch**: Feedforward NN (Linear â†’ ReLU â†’ LayerNorm â†’ Dropout)
- **Fusion**: Multihead Cross-Attention
- **Classifier**: MLP with final softmax output

### 3. Training

- **Loss**: CrossEntropyLoss  
- **Optimizer**: Adam (lr=0.0001)  
- **Epochs**: 15 (early stopping)  
- **Metrics**: Accuracy, F1-score, Confusion Matrix  

### 4. Inference

- Model file: `vit_multimodal_best.pth`  
- Inputs: Leaf image + optional numerical features  
- Outputs: Disease class + confidence score  

### 5. Streamlit Web Interface

- ğŸ”¼ Upload images  
- ğŸ“ˆ Enter optional environmental features  
- ğŸ™ï¸ Voice or ğŸ’¬ text interaction with Gemini-powered chatbot  
- ğŸ”Š Text-to-speech support via `pyttsx3`

---

## ğŸ“ˆ Model Evaluation

| Metric | Value |
|--------|-------|
| **Test Accuracy** | **97.95%** |
| **F1-Score** | 0.94 |
| **Precision** | High (most > 90%) |
| **Recall** | Balanced across classes |

### ğŸ” Observations

- Multimodal ViT outperformed image-only models  
- Cross-attention reduced misclassification  
- High confidence in: Apple Scab, Grape Blight, Potato Early Blight  
- Lower confidence when environmental data was missing

---

## ğŸ–¥ï¸ Results â€“ Web App Overview

### ğŸŒ Homepage Interface

- **Text Input** â€“ Manual queries  
- **Voice Input** â€“ Hands-free diagnosis  
- **Image Upload** â€“ Triggers ViT-based prediction  

> A minimalistic and intuitive UI built with **Streamlit**, tailored for farmers and researchers

### ğŸ§  ViT Inference Example

- **Input:** Leaf image (Citrus tree)  
- **Prediction:** Orange_Huanglongbing (Citrus greening) â€“ **99.06% confidence**  
- **Follow-up:**  
  > _"What diseases can affect this?"_  
  - Gemini responds contextually, explaining secondary infections and symptoms

---

## ğŸ”— GitHub Repository

ğŸ“ [GitHub Repo](https://github.com/sujanshanmugaraj/AI-POWERED-CROP-DISEASE-PREDICTION)

---

## ğŸ¥ Output Demo Video

ğŸ“¹ [Watch Output Video](https://drive.google.com/file/d/1ZEFja6Dy00ZySzIR5okJeSpYQ0QSYZbs/view?usp=sharing)

---

Let me know if you want this converted into a `README.md` file directly or added to your existing repo!
